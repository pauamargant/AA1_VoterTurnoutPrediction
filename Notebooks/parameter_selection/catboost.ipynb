{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Catbost classifier"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from pipeline import *"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:41:04.972313Z","iopub.status.busy":"2023-06-03T14:41:04.971660Z","iopub.status.idle":"2023-06-03T14:41:07.919355Z","shell.execute_reply":"2023-06-03T14:41:07.917844Z","shell.execute_reply.started":"2023-06-03T14:41:04.972264Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["set()\n"]}],"source":["X_train, X_test, y_train, y_test = get_train_test(fname=\"dataset_v1.csv\", balanced=False)\n","X_train,X_val, y_train,y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=rng)\n","X_train = pd.DataFrame(preprocessing_num.fit_transform(X_train,y_train),index=X_train.index,columns=preprocessing_num.get_feature_names_out())\n","X_val = pd.DataFrame(preprocessing_num.transform(X_val),index=X_val.index,columns=preprocessing_num.get_feature_names_out())\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T14:41:07.922631Z","iopub.status.busy":"2023-06-03T14:41:07.922157Z","iopub.status.idle":"2023-06-03T14:41:08.504901Z","shell.execute_reply":"2023-06-03T14:41:08.503563Z","shell.execute_reply.started":"2023-06-03T14:41:07.922587Z"},"trusted":true},"outputs":[],"source":["from catboost import CatBoostClassifier\n","cat_features = [i for i in range(len(num_cols_basic+num_cols_imputate),33)]\n","from sklearn.metrics import make_scorer, f1_score\n","f1_class_0 = make_scorer(f1_score, pos_label=0)\n","\n","from sklearn.metrics import confusion_matrix, \\\n","                  classification_report,  precision_score, recall_score, f1_score, average_precision_score\n","\n","f1_class_0_scorer = make_scorer(f1_score, pos_label=0)\n","f1_class_1_scorer = make_scorer(f1_score, pos_label=1)\n","recall_class_0_scorer = make_scorer(recall_score, pos_label=0)\n","precision_class_0_scorer = make_scorer(precision_score, pos_label=0)\n","average_precision_score_macro = make_scorer(average_precision_score, average='macro')\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We search for the optimal parameters with Optuna"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T16:24:43.962348Z","iopub.status.busy":"2023-06-01T16:24:43.961909Z","iopub.status.idle":"2023-06-01T16:36:24.280964Z","shell.execute_reply":"2023-06-01T16:36:24.279894Z","shell.execute_reply.started":"2023-06-01T16:24:43.962298Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-06-01 16:24:43,976]\u001b[0m A new study created in memory with name: no-name-28f9b46a-c20b-410c-b627-5b05b4832c57\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:24:53,319]\u001b[0m Trial 0 finished with value: 0.5134196400378909 and parameters: {'objective': 'Logloss', 'iterations': 479, 'colsample_bylevel': 0.014090363231753176, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 0 with value: 0.5134196400378909.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:25:07,644]\u001b[0m Trial 1 finished with value: 0.5204669260700389 and parameters: {'objective': 'Logloss', 'iterations': 758, 'colsample_bylevel': 0.015027530768162203, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.5204669260700389.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:25:15,426]\u001b[0m Trial 2 finished with value: 0.5161697428616502 and parameters: {'objective': 'Logloss', 'iterations': 539, 'colsample_bylevel': 0.03226525436467618, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.5204669260700389.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:25:32,188]\u001b[0m Trial 3 finished with value: 0.5176656151419559 and parameters: {'objective': 'Logloss', 'iterations': 739, 'colsample_bylevel': 0.040187987343340004, 'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.5204669260700389.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:25:40,585]\u001b[0m Trial 4 finished with value: 0.5054339507117711 and parameters: {'objective': 'Logloss', 'iterations': 402, 'colsample_bylevel': 0.028412246350613617, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'auto_class_weights': 'Balanced', 'subsample': 0.1270215212349078}. Best is trial 1 with value: 0.5204669260700389.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:25:41,260]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 12.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:25:41,920]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:25:42,810]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 12.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:25:43,470]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 10.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:25:44,221]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 12.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:11,738]\u001b[0m Trial 10 finished with value: 0.5120188266935619 and parameters: {'objective': 'Logloss', 'iterations': 1301, 'colsample_bylevel': 0.09940417788478959, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.5204669260700389.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:26:12,380]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:13,048]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 12.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:13,729]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:14,358]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:14,987]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:15,658]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:16,331]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:17,289]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:17,927]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:18,588]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 10.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:19,412]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:20,208]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:21,047]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:21,704]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:22,482]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:23,212]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:23,832]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 12.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:24,453]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:25,144]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:25,797]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:26,545]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:27,201]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:27,845]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:28,593]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:29,252]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:30,147]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 12.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:26:30,787]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:04,187]\u001b[0m Trial 38 finished with value: 0.516506081187806 and parameters: {'objective': 'Logloss', 'iterations': 956, 'colsample_bylevel': 0.031129537921217802, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.5204669260700389.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:27:04,874]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:05,840]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:06,490]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:07,131]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:07,841]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:08,432]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:09,037]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:09,885]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:10,485]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:11,059]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:11,701]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:12,551]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:27:37,461]\u001b[0m Trial 51 finished with value: 0.5150041911148365 and parameters: {'objective': 'Logloss', 'iterations': 1359, 'colsample_bylevel': 0.050468032267655366, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.5204669260700389.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:28:07,173]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 217.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:28:22,425]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 215.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:28:23,009]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:28:45,587]\u001b[0m Trial 55 finished with value: 0.5205941931127617 and parameters: {'objective': 'Logloss', 'iterations': 1246, 'colsample_bylevel': 0.0515621521544111, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 55 with value: 0.5205941931127617.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:29:06,364]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 210.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:07,577]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:08,457]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:09,327]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:10,105]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:10,889]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:11,528]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:12,263]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:12,893]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:13,482]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:14,059]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:14,637]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:15,256]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:15,909]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:16,539]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:18,410]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 15.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:22,683]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 17.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:24,486]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:25,408]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:26,287]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:26,942]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:27,580]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:57,047]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 758.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:58,411]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 18.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:29:59,568]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 23.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:00,212]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:00,814]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:01,449]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:02,167]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:02,888]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:03,560]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:04,135]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:04,749]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:13,320]\u001b[0m Trial 89 finished with value: 0.517285945072698 and parameters: {'objective': 'Logloss', 'iterations': 303, 'colsample_bylevel': 0.052410676292845876, 'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 55 with value: 0.5205941931127617.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:30:29,580]\u001b[0m Trial 90 finished with value: 0.5092906770075941 and parameters: {'objective': 'Logloss', 'iterations': 700, 'colsample_bylevel': 0.055184728103668874, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 55 with value: 0.5205941931127617.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:30:30,345]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:31,341]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:32,124]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:32,780]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:33,935]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:34,834]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:35,975]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:37,027]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 21.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:37,727]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:38,455]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:39,067]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:39,758]\u001b[0m Trial 102 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:40,374]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:41,586]\u001b[0m Trial 104 pruned. Trial was pruned at iteration 10.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:42,253]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:43,198]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:43,937]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:44,534]\u001b[0m Trial 108 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:45,459]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 9.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:46,355]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:47,130]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:47,819]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:48,490]\u001b[0m Trial 113 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:49,075]\u001b[0m Trial 114 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:49,727]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:50,354]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:51,005]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:51,966]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 15.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:52,807]\u001b[0m Trial 119 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:53,815]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:54,797]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:57,992]\u001b[0m Trial 122 pruned. Trial was pruned at iteration 21.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:58,955]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:30:59,779]\u001b[0m Trial 124 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:01,055]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 10.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:01,680]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:02,566]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:03,155]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:03,815]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:04,448]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:05,266]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:07,586]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 20.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:08,381]\u001b[0m Trial 133 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:09,204]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:09,815]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:10,473]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:12,803]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 15.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:13,790]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:14,571]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:15,448]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:17,168]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 11.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:19,429]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:44,567]\u001b[0m Trial 143 finished with value: 0.5280768593672353 and parameters: {'objective': 'Logloss', 'iterations': 1266, 'colsample_bylevel': 0.05490818695186008, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 143 with value: 0.5280768593672353.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:31:46,034]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:46,687]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:47,291]\u001b[0m Trial 146 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:47,927]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:49,040]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 8.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:49,817]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:50,475]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:31:51,457]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:10,952]\u001b[0m Trial 152 finished with value: 0.5030900283948556 and parameters: {'objective': 'Logloss', 'iterations': 1218, 'colsample_bylevel': 0.060423583004276235, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 143 with value: 0.5280768593672353.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:32:11,965]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:12,574]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:13,488]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 10.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:14,399]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:15,012]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:15,772]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:16,384]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:17,241]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:18,349]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:19,979]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 13.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:20,656]\u001b[0m Trial 163 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:21,624]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:24,016]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 22.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:24,609]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:25,193]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:25,881]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:26,560]\u001b[0m Trial 169 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:28,009]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 11.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:28,746]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:30,120]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 11.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:31,055]\u001b[0m Trial 173 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:31,783]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:32,517]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:33,146]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:33,838]\u001b[0m Trial 177 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:34,587]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:35,236]\u001b[0m Trial 179 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:36,034]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:36,768]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:37,378]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:54,998]\u001b[0m Trial 183 finished with value: 0.52534705974107 and parameters: {'objective': 'Logloss', 'iterations': 336, 'colsample_bylevel': 0.04793980208615374, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 143 with value: 0.5280768593672353.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:32:55,775]\u001b[0m Trial 184 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:56,711]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:58,036]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 19.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:58,632]\u001b[0m Trial 187 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:32:59,392]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:00,057]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:01,689]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 10.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:05,122]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 43.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:05,719]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:06,590]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:28,603]\u001b[0m Trial 194 finished with value: 0.5147322155298715 and parameters: {'objective': 'Logloss', 'iterations': 481, 'colsample_bylevel': 0.05136147473794535, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 143 with value: 0.5280768593672353.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:33:29,460]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:30,420]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:31,146]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:33:31,968]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:45,666]\u001b[0m Trial 199 finished with value: 0.5282476859240345 and parameters: {'objective': 'Logloss', 'iterations': 548, 'colsample_bylevel': 0.0466625323732928, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 199 with value: 0.5282476859240345.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:34:46,658]\u001b[0m Trial 200 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:47,496]\u001b[0m Trial 201 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:48,212]\u001b[0m Trial 202 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:49,209]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:49,825]\u001b[0m Trial 204 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:50,588]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:51,270]\u001b[0m Trial 206 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:52,242]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:52,969]\u001b[0m Trial 208 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:53,596]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:54,281]\u001b[0m Trial 210 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:55,050]\u001b[0m Trial 211 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:55,641]\u001b[0m Trial 212 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:56,227]\u001b[0m Trial 213 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:56,843]\u001b[0m Trial 214 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:57,434]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:58,095]\u001b[0m Trial 216 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:58,683]\u001b[0m Trial 217 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:34:59,277]\u001b[0m Trial 218 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:00,117]\u001b[0m Trial 219 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:00,733]\u001b[0m Trial 220 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:01,632]\u001b[0m Trial 221 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:03,613]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 16.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:04,387]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:05,159]\u001b[0m Trial 224 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:06,006]\u001b[0m Trial 225 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:09,297]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 22.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:10,370]\u001b[0m Trial 227 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:11,055]\u001b[0m Trial 228 pruned. Trial was pruned at iteration 6.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:13,292]\u001b[0m Trial 229 pruned. Trial was pruned at iteration 7.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:14,088]\u001b[0m Trial 230 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:14,981]\u001b[0m Trial 231 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:15,991]\u001b[0m Trial 232 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:16,704]\u001b[0m Trial 233 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:17,664]\u001b[0m Trial 234 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:18,254]\u001b[0m Trial 235 pruned. Trial was pruned at iteration 5.\u001b[0m\n","\u001b[32m[I 2023-06-01 16:35:52,996]\u001b[0m Trial 236 finished with value: 0.5181834000348008 and parameters: {'objective': 'Logloss', 'iterations': 967, 'colsample_bylevel': 0.08025541300761432, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 199 with value: 0.5282476859240345.\u001b[0m\n","/tmp/ipykernel_32/2468516105.py:51: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n","  pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","\u001b[32m[I 2023-06-01 16:36:24,198]\u001b[0m Trial 237 finished with value: 0.5204778156996587 and parameters: {'objective': 'Logloss', 'iterations': 968, 'colsample_bylevel': 0.08324489618882672, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'auto_class_weights': 'Balanced'}. Best is trial 199 with value: 0.5282476859240345.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Number of finished trials: 238\n","Best trial:\n","  Value: 0.5282476859240345\n","  Params: \n","    objective: Logloss\n","    iterations: 548\n","    colsample_bylevel: 0.0466625323732928\n","    depth: 12\n","    boosting_type: Ordered\n","    bootstrap_type: MVS\n","    auto_class_weights: Balanced\n"]}],"source":["import numpy as np\n","import optuna\n","from optuna.integration import CatBoostPruningCallback\n","\n","import catboost as cb\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","\n","\n","def objective(trial: optuna.Trial) -> float:\n","    data, target = X_train, y_train\n","    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n","    \n","    param = {\n","        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\"]),\n","        \"iterations\": trial.suggest_int(\"iterations\",300,1500),\n","        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log=True),\n","        \"depth\": trial.suggest_int(\"depth\", 1,12),\n","        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Plain\",\"Ordered\"]),\n","        \"bootstrap_type\": trial.suggest_categorical(\n","            \"bootstrap_type\", [ \"Bernoulli\", \"MVS\"]\n","        ),\n","        \"auto_class_weights\": trial.suggest_categorical(\"auto_class_weights\", [\"Balanced\"]),\n","        \"used_ram_limit\": \"25gb\",\n","        \"eval_metric\": \"PRAUC\",\n","        \"cat_features\": cat_features,\n","        \n","    }\n","\n","    if param[\"bootstrap_type\"] == \"Bayesian\":\n","        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n","    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n","        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log=True)\n","\n","    gbm = cb.CatBoostClassifier(**param)\n","\n","    pruning_callback = CatBoostPruningCallback(trial, \"PRAUC\")\n","    gbm.fit(\n","        train_x,\n","        train_y,\n","        eval_set=[(valid_x, valid_y)],\n","        verbose=0,\n","        early_stopping_rounds=120,\n","        callbacks=[pruning_callback],\n","    )\n","\n","    # evoke pruning manually.\n","    pruning_callback.check_pruned()\n","\n","    preds = gbm.predict(valid_x)\n","    pred_labels = np.rint(preds)\n","    f1 = f1_score(valid_y, pred_labels,pos_label=0)\n","\n","    return f1\n","\n","\n","if __name__ == \"__main__\":\n","    study = optuna.create_study(\n","        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"maximize\"\n","    )\n","    study.optimize(objective, n_trials=300, timeout=700)\n","\n","    print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We train a catboost classifier with the parameters found"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:02:13.124516Z","iopub.status.busy":"2023-06-03T15:02:13.124014Z","iopub.status.idle":"2023-06-03T15:04:26.506844Z","shell.execute_reply":"2023-06-03T15:04:26.505517Z","shell.execute_reply.started":"2023-06-03T15:02:13.124479Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"489060a6591c489f9929916a700af1fe","version_major":2,"version_minor":0},"text/plain":["MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Learning rate set to 0.089966\n","0:\tlearn: 0.6786690\ttotal: 49.1ms\tremaining: 27s\n","1:\tlearn: 0.6586176\ttotal: 581ms\tremaining: 2m 39s\n","2:\tlearn: 0.6457912\ttotal: 680ms\tremaining: 2m 3s\n","3:\tlearn: 0.6331633\ttotal: 780ms\tremaining: 1m 46s\n","4:\tlearn: 0.6208888\ttotal: 1.31s\tremaining: 2m 22s\n","5:\tlearn: 0.6110197\ttotal: 1.84s\tremaining: 2m 46s\n","6:\tlearn: 0.6110197\ttotal: 1.86s\tremaining: 2m 24s\n","7:\tlearn: 0.6110196\ttotal: 1.87s\tremaining: 2m 6s\n","8:\tlearn: 0.6045797\ttotal: 2s\tremaining: 2m\n","9:\tlearn: 0.6014278\ttotal: 2.06s\tremaining: 1m 51s\n","10:\tlearn: 0.5957031\ttotal: 2.18s\tremaining: 1m 46s\n","11:\tlearn: 0.5902666\ttotal: 2.37s\tremaining: 1m 46s\n","12:\tlearn: 0.5896985\ttotal: 2.39s\tremaining: 1m 38s\n","13:\tlearn: 0.5851644\ttotal: 3.03s\tremaining: 1m 55s\n","14:\tlearn: 0.5818355\ttotal: 3.18s\tremaining: 1m 53s\n","15:\tlearn: 0.5818355\ttotal: 3.2s\tremaining: 1m 46s\n","16:\tlearn: 0.5795386\ttotal: 3.25s\tremaining: 1m 41s\n","17:\tlearn: 0.5769619\ttotal: 3.31s\tremaining: 1m 37s\n","18:\tlearn: 0.5741536\ttotal: 3.71s\tremaining: 1m 43s\n","19:\tlearn: 0.5741535\ttotal: 3.73s\tremaining: 1m 38s\n","20:\tlearn: 0.5732887\ttotal: 3.77s\tremaining: 1m 35s\n","21:\tlearn: 0.5732887\ttotal: 3.79s\tremaining: 1m 30s\n","22:\tlearn: 0.5732886\ttotal: 3.81s\tremaining: 1m 27s\n","23:\tlearn: 0.5727483\ttotal: 3.82s\tremaining: 1m 23s\n","24:\tlearn: 0.5701488\ttotal: 4.13s\tremaining: 1m 26s\n","25:\tlearn: 0.5701488\ttotal: 4.14s\tremaining: 1m 23s\n","26:\tlearn: 0.5701488\ttotal: 4.16s\tremaining: 1m 20s\n","27:\tlearn: 0.5686857\ttotal: 4.22s\tremaining: 1m 18s\n","28:\tlearn: 0.5686857\ttotal: 4.24s\tremaining: 1m 16s\n","29:\tlearn: 0.5673143\ttotal: 4.3s\tremaining: 1m 14s\n","30:\tlearn: 0.5656545\ttotal: 4.81s\tremaining: 1m 20s\n","31:\tlearn: 0.5655489\ttotal: 4.83s\tremaining: 1m 18s\n","32:\tlearn: 0.5655489\ttotal: 4.84s\tremaining: 1m 15s\n","33:\tlearn: 0.5651053\ttotal: 4.88s\tremaining: 1m 14s\n","34:\tlearn: 0.5651053\ttotal: 4.89s\tremaining: 1m 11s\n","35:\tlearn: 0.5648539\ttotal: 4.91s\tremaining: 1m 10s\n","36:\tlearn: 0.5648539\ttotal: 4.93s\tremaining: 1m 8s\n","37:\tlearn: 0.5637746\ttotal: 5.16s\tremaining: 1m 9s\n","38:\tlearn: 0.5634969\ttotal: 5.19s\tremaining: 1m 7s\n","39:\tlearn: 0.5634969\ttotal: 5.2s\tremaining: 1m 6s\n","40:\tlearn: 0.5634969\ttotal: 5.22s\tremaining: 1m 4s\n","41:\tlearn: 0.5628657\ttotal: 5.25s\tremaining: 1m 3s\n","42:\tlearn: 0.5628645\ttotal: 5.28s\tremaining: 1m 2s\n","43:\tlearn: 0.5624501\ttotal: 5.32s\tremaining: 1m 1s\n","44:\tlearn: 0.5613370\ttotal: 5.85s\tremaining: 1m 5s\n","45:\tlearn: 0.5604874\ttotal: 5.89s\tremaining: 1m 4s\n","46:\tlearn: 0.5602380\ttotal: 5.94s\tremaining: 1m 3s\n","47:\tlearn: 0.5598253\ttotal: 6s\tremaining: 1m 2s\n","48:\tlearn: 0.5596547\ttotal: 6.03s\tremaining: 1m 1s\n","49:\tlearn: 0.5595773\ttotal: 6.05s\tremaining: 1m\n","50:\tlearn: 0.5589917\ttotal: 6.61s\tremaining: 1m 4s\n","51:\tlearn: 0.5589917\ttotal: 6.63s\tremaining: 1m 3s\n","52:\tlearn: 0.5588118\ttotal: 6.67s\tremaining: 1m 2s\n","53:\tlearn: 0.5588118\ttotal: 6.68s\tremaining: 1m 1s\n","54:\tlearn: 0.5585552\ttotal: 6.75s\tremaining: 1m\n","55:\tlearn: 0.5585552\ttotal: 6.76s\tremaining: 59.7s\n","56:\tlearn: 0.5584867\ttotal: 6.79s\tremaining: 58.7s\n","57:\tlearn: 0.5584609\ttotal: 6.85s\tremaining: 58.1s\n","58:\tlearn: 0.5584609\ttotal: 6.87s\tremaining: 57.2s\n","59:\tlearn: 0.5584609\ttotal: 6.88s\tremaining: 56.2s\n","60:\tlearn: 0.5582850\ttotal: 6.9s\tremaining: 55.4s\n","61:\tlearn: 0.5582622\ttotal: 6.93s\tremaining: 54.6s\n","62:\tlearn: 0.5582622\ttotal: 6.95s\tremaining: 53.8s\n","63:\tlearn: 0.5582622\ttotal: 6.97s\tremaining: 52.9s\n","64:\tlearn: 0.5576201\ttotal: 7.52s\tremaining: 56.1s\n","65:\tlearn: 0.5575605\ttotal: 7.54s\tremaining: 55.3s\n","66:\tlearn: 0.5573183\ttotal: 7.67s\tremaining: 55.3s\n","67:\tlearn: 0.5571460\ttotal: 7.71s\tremaining: 54.6s\n","68:\tlearn: 0.5571460\ttotal: 7.73s\tremaining: 53.9s\n","69:\tlearn: 0.5571460\ttotal: 7.74s\tremaining: 53.1s\n","70:\tlearn: 0.5567188\ttotal: 7.82s\tremaining: 52.8s\n","71:\tlearn: 0.5567188\ttotal: 7.83s\tremaining: 52s\n","72:\tlearn: 0.5566545\ttotal: 7.89s\tremaining: 51.5s\n","73:\tlearn: 0.5564295\ttotal: 7.95s\tremaining: 51.1s\n","74:\tlearn: 0.5564295\ttotal: 7.97s\tremaining: 50.5s\n","75:\tlearn: 0.5562955\ttotal: 8s\tremaining: 49.9s\n","76:\tlearn: 0.5562955\ttotal: 8.01s\tremaining: 49.2s\n","77:\tlearn: 0.5561822\ttotal: 8.26s\tremaining: 50s\n","78:\tlearn: 0.5561822\ttotal: 8.27s\tremaining: 49.3s\n","79:\tlearn: 0.5556217\ttotal: 8.77s\tremaining: 51.5s\n","80:\tlearn: 0.5555998\ttotal: 8.8s\tremaining: 50.9s\n","81:\tlearn: 0.5555977\ttotal: 8.82s\tremaining: 50.4s\n","82:\tlearn: 0.5555977\ttotal: 8.84s\tremaining: 49.8s\n","83:\tlearn: 0.5555975\ttotal: 8.87s\tremaining: 49.2s\n","84:\tlearn: 0.5555975\ttotal: 8.88s\tremaining: 48.6s\n","85:\tlearn: 0.5551479\ttotal: 9.49s\tremaining: 51.2s\n","86:\tlearn: 0.5551479\ttotal: 9.51s\tremaining: 50.6s\n","87:\tlearn: 0.5551479\ttotal: 9.52s\tremaining: 50s\n","88:\tlearn: 0.5550121\ttotal: 9.56s\tremaining: 49.5s\n","89:\tlearn: 0.5549988\ttotal: 9.58s\tremaining: 49s\n","90:\tlearn: 0.5548614\ttotal: 9.73s\tremaining: 49.1s\n","91:\tlearn: 0.5545623\ttotal: 9.78s\tremaining: 48.7s\n","92:\tlearn: 0.5544972\ttotal: 9.81s\tremaining: 48.2s\n","93:\tlearn: 0.5543546\ttotal: 9.86s\tremaining: 47.8s\n","94:\tlearn: 0.5543217\ttotal: 9.88s\tremaining: 47.3s\n","95:\tlearn: 0.5543194\ttotal: 9.92s\tremaining: 46.9s\n","96:\tlearn: 0.5540556\ttotal: 10s\tremaining: 46.8s\n","97:\tlearn: 0.5540556\ttotal: 10s\tremaining: 46.3s\n","98:\tlearn: 0.5540194\ttotal: 10.1s\tremaining: 46s\n","99:\tlearn: 0.5539940\ttotal: 10.2s\tremaining: 45.7s\n","100:\tlearn: 0.5539940\ttotal: 10.2s\tremaining: 45.2s\n","101:\tlearn: 0.5538414\ttotal: 10.2s\tremaining: 44.8s\n","102:\tlearn: 0.5538368\ttotal: 10.2s\tremaining: 44.4s\n","103:\tlearn: 0.5538368\ttotal: 10.2s\tremaining: 43.9s\n","104:\tlearn: 0.5535869\ttotal: 10.3s\tremaining: 43.7s\n","105:\tlearn: 0.5534513\ttotal: 10.3s\tremaining: 43.3s\n","106:\tlearn: 0.5534513\ttotal: 10.4s\tremaining: 42.9s\n","107:\tlearn: 0.5533334\ttotal: 10.4s\tremaining: 42.7s\n","108:\tlearn: 0.5533090\ttotal: 10.5s\tremaining: 42.4s\n","109:\tlearn: 0.5533090\ttotal: 10.5s\tremaining: 42s\n","110:\tlearn: 0.5533086\ttotal: 10.5s\tremaining: 41.6s\n","111:\tlearn: 0.5531444\ttotal: 10.6s\tremaining: 41.5s\n","112:\tlearn: 0.5526393\ttotal: 10.8s\tremaining: 41.8s\n","113:\tlearn: 0.5526393\ttotal: 10.8s\tremaining: 41.4s\n","114:\tlearn: 0.5526393\ttotal: 10.8s\tremaining: 41s\n","115:\tlearn: 0.5526393\ttotal: 10.9s\tremaining: 40.6s\n","116:\tlearn: 0.5526393\ttotal: 10.9s\tremaining: 40.2s\n","117:\tlearn: 0.5525452\ttotal: 10.9s\tremaining: 40.1s\n","118:\tlearn: 0.5525452\ttotal: 11s\tremaining: 39.7s\n","119:\tlearn: 0.5524993\ttotal: 11s\tremaining: 39.4s\n","120:\tlearn: 0.5524763\ttotal: 11s\tremaining: 39.2s\n","121:\tlearn: 0.5520894\ttotal: 11.2s\tremaining: 39.2s\n","122:\tlearn: 0.5518280\ttotal: 11.7s\tremaining: 40.5s\n","123:\tlearn: 0.5517778\ttotal: 11.7s\tremaining: 40.1s\n","124:\tlearn: 0.5517593\ttotal: 11.7s\tremaining: 39.9s\n","125:\tlearn: 0.5517593\ttotal: 11.7s\tremaining: 39.5s\n","126:\tlearn: 0.5515460\ttotal: 11.8s\tremaining: 39.3s\n","127:\tlearn: 0.5514583\ttotal: 11.8s\tremaining: 39s\n","128:\tlearn: 0.5514583\ttotal: 11.8s\tremaining: 38.7s\n","129:\tlearn: 0.5514583\ttotal: 11.9s\tremaining: 38.3s\n","130:\tlearn: 0.5514334\ttotal: 11.9s\tremaining: 38s\n","131:\tlearn: 0.5513345\ttotal: 12s\tremaining: 37.9s\n","132:\tlearn: 0.5513345\ttotal: 12s\tremaining: 37.6s\n","133:\tlearn: 0.5512261\ttotal: 12s\tremaining: 37.3s\n","134:\tlearn: 0.5512257\ttotal: 12s\tremaining: 37s\n","135:\tlearn: 0.5512257\ttotal: 12s\tremaining: 36.7s\n","136:\tlearn: 0.5512257\ttotal: 12.1s\tremaining: 36.4s\n","137:\tlearn: 0.5511481\ttotal: 12.1s\tremaining: 36.1s\n","138:\tlearn: 0.5511453\ttotal: 12.1s\tremaining: 35.9s\n","139:\tlearn: 0.5511308\ttotal: 12.2s\tremaining: 35.7s\n","140:\tlearn: 0.5511308\ttotal: 12.2s\tremaining: 35.4s\n","141:\tlearn: 0.5510807\ttotal: 12.2s\tremaining: 35.1s\n","142:\tlearn: 0.5509218\ttotal: 12.3s\tremaining: 34.9s\n","143:\tlearn: 0.5509218\ttotal: 12.3s\tremaining: 34.6s\n","144:\tlearn: 0.5508048\ttotal: 12.3s\tremaining: 34.4s\n","145:\tlearn: 0.5504222\ttotal: 12.5s\tremaining: 34.6s\n","146:\tlearn: 0.5504203\ttotal: 12.5s\tremaining: 34.4s\n","147:\tlearn: 0.5501512\ttotal: 13.1s\tremaining: 35.6s\n","148:\tlearn: 0.5498946\ttotal: 13.1s\tremaining: 35.4s\n","149:\tlearn: 0.5498108\ttotal: 13.2s\tremaining: 35.2s\n","150:\tlearn: 0.5498108\ttotal: 13.2s\tremaining: 34.9s\n","151:\tlearn: 0.5498108\ttotal: 13.2s\tremaining: 34.6s\n","152:\tlearn: 0.5498084\ttotal: 13.2s\tremaining: 34.4s\n","153:\tlearn: 0.5497714\ttotal: 13.3s\tremaining: 34.1s\n","154:\tlearn: 0.5496268\ttotal: 13.3s\tremaining: 33.9s\n","155:\tlearn: 0.5496268\ttotal: 13.3s\tremaining: 33.6s\n","156:\tlearn: 0.5496268\ttotal: 13.3s\tremaining: 33.4s\n","157:\tlearn: 0.5496222\ttotal: 13.4s\tremaining: 33.1s\n","158:\tlearn: 0.5495356\ttotal: 13.4s\tremaining: 32.9s\n","159:\tlearn: 0.5495356\ttotal: 13.4s\tremaining: 32.7s\n","160:\tlearn: 0.5493167\ttotal: 13.4s\tremaining: 32.5s\n","161:\tlearn: 0.5493039\ttotal: 13.5s\tremaining: 32.2s\n","162:\tlearn: 0.5492989\ttotal: 13.5s\tremaining: 32s\n","163:\tlearn: 0.5491056\ttotal: 14s\tremaining: 33s\n","164:\tlearn: 0.5487451\ttotal: 14.5s\tremaining: 33.9s\n","165:\tlearn: 0.5484955\ttotal: 14.6s\tremaining: 33.7s\n","166:\tlearn: 0.5484433\ttotal: 14.6s\tremaining: 33.5s\n","167:\tlearn: 0.5484433\ttotal: 14.6s\tremaining: 33.3s\n","168:\tlearn: 0.5482595\ttotal: 15.3s\tremaining: 34.4s\n","169:\tlearn: 0.5482595\ttotal: 15.3s\tremaining: 34.2s\n","170:\tlearn: 0.5473063\ttotal: 15.9s\tremaining: 35.3s\n","171:\tlearn: 0.5471203\ttotal: 16.4s\tremaining: 36.1s\n","172:\tlearn: 0.5471203\ttotal: 16.5s\tremaining: 35.9s\n","173:\tlearn: 0.5468643\ttotal: 17s\tremaining: 36.7s\n","174:\tlearn: 0.5462143\ttotal: 17.5s\tremaining: 37.6s\n","175:\tlearn: 0.5462060\ttotal: 17.6s\tremaining: 37.4s\n","176:\tlearn: 0.5460532\ttotal: 18.1s\tremaining: 38.1s\n","177:\tlearn: 0.5458367\ttotal: 18.5s\tremaining: 38.7s\n","178:\tlearn: 0.5457007\ttotal: 18.9s\tremaining: 39.3s\n","179:\tlearn: 0.5457007\ttotal: 19s\tremaining: 39s\n","180:\tlearn: 0.5457007\ttotal: 19s\tremaining: 38.7s\n","181:\tlearn: 0.5455687\ttotal: 19.4s\tremaining: 39.2s\n","182:\tlearn: 0.5453166\ttotal: 19.6s\tremaining: 39.3s\n","183:\tlearn: 0.5453166\ttotal: 19.6s\tremaining: 39s\n","184:\tlearn: 0.5453166\ttotal: 19.6s\tremaining: 38.8s\n","185:\tlearn: 0.5451346\ttotal: 20.2s\tremaining: 39.5s\n","186:\tlearn: 0.5449023\ttotal: 20.8s\tremaining: 40.4s\n","187:\tlearn: 0.5449023\ttotal: 20.8s\tremaining: 40.1s\n","188:\tlearn: 0.5448775\ttotal: 20.9s\tremaining: 39.9s\n","189:\tlearn: 0.5448775\ttotal: 20.9s\tremaining: 39.6s\n","190:\tlearn: 0.5448775\ttotal: 20.9s\tremaining: 39.3s\n","191:\tlearn: 0.5448775\ttotal: 20.9s\tremaining: 39s\n","192:\tlearn: 0.5448775\ttotal: 21s\tremaining: 38.8s\n","193:\tlearn: 0.5448775\ttotal: 21s\tremaining: 38.5s\n","194:\tlearn: 0.5446323\ttotal: 21.6s\tremaining: 39.3s\n","195:\tlearn: 0.5443241\ttotal: 22.3s\tremaining: 40.2s\n","196:\tlearn: 0.5440142\ttotal: 22.8s\tremaining: 40.9s\n","197:\tlearn: 0.5438049\ttotal: 23.4s\tremaining: 41.6s\n","198:\tlearn: 0.5438049\ttotal: 23.4s\tremaining: 41.3s\n","199:\tlearn: 0.5437851\ttotal: 23.5s\tremaining: 41.1s\n","200:\tlearn: 0.5435044\ttotal: 24s\tremaining: 41.7s\n","201:\tlearn: 0.5435044\ttotal: 24s\tremaining: 41.4s\n","202:\tlearn: 0.5435044\ttotal: 24s\tremaining: 41.1s\n","203:\tlearn: 0.5433948\ttotal: 24.5s\tremaining: 41.6s\n","204:\tlearn: 0.5433867\ttotal: 24.5s\tremaining: 41.3s\n","205:\tlearn: 0.5433867\ttotal: 24.6s\tremaining: 41s\n","206:\tlearn: 0.5432327\ttotal: 25s\tremaining: 41.5s\n","207:\tlearn: 0.5431997\ttotal: 25.6s\tremaining: 42.2s\n","208:\tlearn: 0.5431997\ttotal: 25.7s\tremaining: 41.9s\n","209:\tlearn: 0.5431075\ttotal: 26.2s\tremaining: 42.4s\n","210:\tlearn: 0.5431075\ttotal: 26.2s\tremaining: 42.1s\n","211:\tlearn: 0.5431075\ttotal: 26.2s\tremaining: 41.8s\n","212:\tlearn: 0.5431042\ttotal: 26.2s\tremaining: 41.5s\n","213:\tlearn: 0.5430854\ttotal: 26.3s\tremaining: 41.3s\n","214:\tlearn: 0.5430847\ttotal: 26.3s\tremaining: 41s\n","215:\tlearn: 0.5428586\ttotal: 26.8s\tremaining: 41.4s\n","216:\tlearn: 0.5428586\ttotal: 26.8s\tremaining: 41.2s\n","217:\tlearn: 0.5426698\ttotal: 27.3s\tremaining: 41.6s\n","218:\tlearn: 0.5426698\ttotal: 27.4s\tremaining: 41.3s\n","219:\tlearn: 0.5424814\ttotal: 27.8s\tremaining: 41.8s\n","220:\tlearn: 0.5422914\ttotal: 28.3s\tremaining: 42.1s\n","221:\tlearn: 0.5421189\ttotal: 28.5s\tremaining: 42.1s\n","222:\tlearn: 0.5418215\ttotal: 29s\tremaining: 42.5s\n","223:\tlearn: 0.5418185\ttotal: 29s\tremaining: 42.3s\n","224:\tlearn: 0.5416342\ttotal: 29.6s\tremaining: 42.8s\n","225:\tlearn: 0.5414181\ttotal: 30.1s\tremaining: 43.2s\n","226:\tlearn: 0.5414181\ttotal: 30.2s\tremaining: 42.9s\n","227:\tlearn: 0.5414181\ttotal: 30.2s\tremaining: 42.6s\n","228:\tlearn: 0.5412496\ttotal: 30.7s\tremaining: 43.1s\n","229:\tlearn: 0.5411980\ttotal: 31.2s\tremaining: 43.4s\n","230:\tlearn: 0.5411978\ttotal: 31.2s\tremaining: 43.1s\n","231:\tlearn: 0.5410554\ttotal: 31.7s\tremaining: 43.5s\n","232:\tlearn: 0.5410554\ttotal: 31.7s\tremaining: 43.2s\n","233:\tlearn: 0.5409198\ttotal: 32.3s\tremaining: 43.6s\n","234:\tlearn: 0.5409198\ttotal: 32.3s\tremaining: 43.3s\n","235:\tlearn: 0.5406869\ttotal: 32.8s\tremaining: 43.6s\n","236:\tlearn: 0.5406869\ttotal: 32.8s\tremaining: 43.3s\n","237:\tlearn: 0.5405782\ttotal: 33.3s\tremaining: 43.7s\n","238:\tlearn: 0.5405782\ttotal: 33.3s\tremaining: 43.4s\n","239:\tlearn: 0.5405782\ttotal: 33.3s\tremaining: 43.1s\n","240:\tlearn: 0.5402193\ttotal: 33.9s\tremaining: 43.4s\n","241:\tlearn: 0.5401240\ttotal: 34.4s\tremaining: 43.8s\n","242:\tlearn: 0.5401240\ttotal: 34.4s\tremaining: 43.5s\n","243:\tlearn: 0.5401240\ttotal: 34.5s\tremaining: 43.2s\n","244:\tlearn: 0.5399763\ttotal: 34.9s\tremaining: 43.4s\n","245:\tlearn: 0.5397770\ttotal: 35.3s\tremaining: 43.6s\n","246:\tlearn: 0.5397770\ttotal: 35.3s\tremaining: 43.3s\n","247:\tlearn: 0.5397763\ttotal: 35.3s\tremaining: 43s\n","248:\tlearn: 0.5396835\ttotal: 36s\tremaining: 43.5s\n","249:\tlearn: 0.5396835\ttotal: 36s\tremaining: 43.2s\n","250:\tlearn: 0.5396808\ttotal: 36s\tremaining: 42.9s\n","251:\tlearn: 0.5393634\ttotal: 36.6s\tremaining: 43.3s\n","252:\tlearn: 0.5393630\ttotal: 36.7s\tremaining: 43s\n","253:\tlearn: 0.5392699\ttotal: 37.2s\tremaining: 43.3s\n","254:\tlearn: 0.5391323\ttotal: 37.7s\tremaining: 43.6s\n","255:\tlearn: 0.5387511\ttotal: 38.2s\tremaining: 43.8s\n","256:\tlearn: 0.5387253\ttotal: 38.3s\tremaining: 43.7s\n","257:\tlearn: 0.5386801\ttotal: 38.9s\tremaining: 44s\n","258:\tlearn: 0.5386129\ttotal: 39.4s\tremaining: 44.3s\n","259:\tlearn: 0.5386121\ttotal: 39.5s\tremaining: 44s\n","260:\tlearn: 0.5386121\ttotal: 39.5s\tremaining: 43.7s\n","261:\tlearn: 0.5385838\ttotal: 39.5s\tremaining: 43.4s\n","262:\tlearn: 0.5385749\ttotal: 39.6s\tremaining: 43.2s\n","263:\tlearn: 0.5385019\ttotal: 40.3s\tremaining: 43.7s\n","264:\tlearn: 0.5383828\ttotal: 40.9s\tremaining: 44s\n","265:\tlearn: 0.5383828\ttotal: 40.9s\tremaining: 43.7s\n","266:\tlearn: 0.5383199\ttotal: 41.5s\tremaining: 43.9s\n","267:\tlearn: 0.5382405\ttotal: 42s\tremaining: 44.2s\n","268:\tlearn: 0.5382332\ttotal: 42s\tremaining: 43.9s\n","269:\tlearn: 0.5382332\ttotal: 42.1s\tremaining: 43.6s\n","270:\tlearn: 0.5382027\ttotal: 42.1s\tremaining: 43.3s\n","271:\tlearn: 0.5380024\ttotal: 42.6s\tremaining: 43.5s\n","272:\tlearn: 0.5379842\ttotal: 42.6s\tremaining: 43.2s\n","273:\tlearn: 0.5379672\ttotal: 43.1s\tremaining: 43.5s\n","274:\tlearn: 0.5377586\ttotal: 43.7s\tremaining: 43.7s\n","275:\tlearn: 0.5374216\ttotal: 44.2s\tremaining: 43.9s\n","276:\tlearn: 0.5373025\ttotal: 44.8s\tremaining: 44.2s\n","277:\tlearn: 0.5373025\ttotal: 44.8s\tremaining: 43.8s\n","278:\tlearn: 0.5372214\ttotal: 45.5s\tremaining: 44.2s\n","279:\tlearn: 0.5370763\ttotal: 46.2s\tremaining: 44.6s\n","280:\tlearn: 0.5370760\ttotal: 46.3s\tremaining: 44.3s\n","281:\tlearn: 0.5370740\ttotal: 46.3s\tremaining: 44s\n","282:\tlearn: 0.5370538\ttotal: 46.9s\tremaining: 44.3s\n","283:\tlearn: 0.5368988\ttotal: 47.5s\tremaining: 44.5s\n","284:\tlearn: 0.5368988\ttotal: 47.6s\tremaining: 44.2s\n","285:\tlearn: 0.5368955\ttotal: 47.6s\tremaining: 43.9s\n","286:\tlearn: 0.5367031\ttotal: 48.2s\tremaining: 44.2s\n","287:\tlearn: 0.5366393\ttotal: 48.7s\tremaining: 44.3s\n","288:\tlearn: 0.5365930\ttotal: 48.8s\tremaining: 44s\n","289:\tlearn: 0.5364619\ttotal: 49.3s\tremaining: 44.2s\n","290:\tlearn: 0.5362475\ttotal: 49.9s\tremaining: 44.4s\n","291:\tlearn: 0.5361874\ttotal: 50.2s\tremaining: 44.4s\n","292:\tlearn: 0.5360904\ttotal: 50.7s\tremaining: 44.5s\n","293:\tlearn: 0.5360904\ttotal: 50.7s\tremaining: 44.2s\n","294:\tlearn: 0.5359752\ttotal: 51.2s\tremaining: 44.3s\n","295:\tlearn: 0.5358885\ttotal: 51.3s\tremaining: 44s\n","296:\tlearn: 0.5358885\ttotal: 51.3s\tremaining: 43.7s\n","297:\tlearn: 0.5357905\ttotal: 51.9s\tremaining: 43.9s\n","298:\tlearn: 0.5357334\ttotal: 52.4s\tremaining: 44s\n","299:\tlearn: 0.5354388\ttotal: 52.9s\tremaining: 44.1s\n","300:\tlearn: 0.5354386\ttotal: 53s\tremaining: 43.8s\n","301:\tlearn: 0.5351666\ttotal: 53.5s\tremaining: 43.9s\n","302:\tlearn: 0.5351666\ttotal: 53.5s\tremaining: 43.6s\n","303:\tlearn: 0.5351591\ttotal: 53.5s\tremaining: 43.3s\n","304:\tlearn: 0.5351591\ttotal: 53.5s\tremaining: 43s\n","305:\tlearn: 0.5349254\ttotal: 54.1s\tremaining: 43.2s\n","306:\tlearn: 0.5349254\ttotal: 54.1s\tremaining: 42.8s\n","307:\tlearn: 0.5348674\ttotal: 54.5s\tremaining: 42.8s\n","308:\tlearn: 0.5348674\ttotal: 54.5s\tremaining: 42.5s\n","309:\tlearn: 0.5347850\ttotal: 55.1s\tremaining: 42.7s\n","310:\tlearn: 0.5346830\ttotal: 55.6s\tremaining: 42.8s\n","311:\tlearn: 0.5346578\ttotal: 56.2s\tremaining: 42.8s\n","312:\tlearn: 0.5345438\ttotal: 56.7s\tremaining: 42.9s\n","313:\tlearn: 0.5345054\ttotal: 56.9s\tremaining: 42.8s\n","314:\tlearn: 0.5344867\ttotal: 57.4s\tremaining: 42.8s\n","315:\tlearn: 0.5344756\ttotal: 57.5s\tremaining: 42.5s\n","316:\tlearn: 0.5344174\ttotal: 58s\tremaining: 42.6s\n","317:\tlearn: 0.5343660\ttotal: 58.5s\tremaining: 42.7s\n","318:\tlearn: 0.5343630\ttotal: 58.6s\tremaining: 42.4s\n","319:\tlearn: 0.5343069\ttotal: 59.1s\tremaining: 42.5s\n","320:\tlearn: 0.5343062\ttotal: 59.1s\tremaining: 42.2s\n","321:\tlearn: 0.5343062\ttotal: 59.1s\tremaining: 41.9s\n","322:\tlearn: 0.5342391\ttotal: 59.7s\tremaining: 42s\n","323:\tlearn: 0.5341561\ttotal: 1m\tremaining: 42s\n","324:\tlearn: 0.5340984\ttotal: 1m\tremaining: 42.2s\n","325:\tlearn: 0.5340971\ttotal: 1m\tremaining: 41.9s\n","326:\tlearn: 0.5340801\ttotal: 1m\tremaining: 41.6s\n","327:\tlearn: 0.5340801\ttotal: 1m\tremaining: 41.3s\n","328:\tlearn: 0.5339198\ttotal: 1m 1s\tremaining: 41.3s\n","329:\tlearn: 0.5338108\ttotal: 1m 2s\tremaining: 41.4s\n","330:\tlearn: 0.5337758\ttotal: 1m 2s\tremaining: 41.4s\n","331:\tlearn: 0.5335691\ttotal: 1m 3s\tremaining: 41.4s\n","332:\tlearn: 0.5334379\ttotal: 1m 3s\tremaining: 41.5s\n","333:\tlearn: 0.5334345\ttotal: 1m 3s\tremaining: 41.2s\n","334:\tlearn: 0.5333381\ttotal: 1m 4s\tremaining: 41.3s\n","335:\tlearn: 0.5332746\ttotal: 1m 4s\tremaining: 41.4s\n","336:\tlearn: 0.5332746\ttotal: 1m 4s\tremaining: 41.1s\n","337:\tlearn: 0.5332746\ttotal: 1m 4s\tremaining: 40.7s\n","338:\tlearn: 0.5330930\ttotal: 1m 5s\tremaining: 40.8s\n","339:\tlearn: 0.5330930\ttotal: 1m 5s\tremaining: 40.5s\n","340:\tlearn: 0.5330930\ttotal: 1m 5s\tremaining: 40.2s\n","341:\tlearn: 0.5329465\ttotal: 1m 6s\tremaining: 40.2s\n","342:\tlearn: 0.5328233\ttotal: 1m 6s\tremaining: 40.2s\n","343:\tlearn: 0.5327680\ttotal: 1m 6s\tremaining: 40s\n","344:\tlearn: 0.5327310\ttotal: 1m 7s\tremaining: 40s\n","345:\tlearn: 0.5327303\ttotal: 1m 7s\tremaining: 39.7s\n","346:\tlearn: 0.5327170\ttotal: 1m 7s\tremaining: 39.5s\n","347:\tlearn: 0.5327169\ttotal: 1m 7s\tremaining: 39.2s\n","348:\tlearn: 0.5324572\ttotal: 1m 8s\tremaining: 39.2s\n","349:\tlearn: 0.5324327\ttotal: 1m 8s\tremaining: 39.2s\n","350:\tlearn: 0.5324327\ttotal: 1m 8s\tremaining: 38.9s\n","351:\tlearn: 0.5319628\ttotal: 1m 9s\tremaining: 38.9s\n","352:\tlearn: 0.5317893\ttotal: 1m 9s\tremaining: 38.9s\n","353:\tlearn: 0.5317648\ttotal: 1m 10s\tremaining: 38.9s\n","354:\tlearn: 0.5317584\ttotal: 1m 10s\tremaining: 38.6s\n","355:\tlearn: 0.5317584\ttotal: 1m 10s\tremaining: 38.3s\n","356:\tlearn: 0.5317251\ttotal: 1m 10s\tremaining: 38.3s\n","357:\tlearn: 0.5317246\ttotal: 1m 10s\tremaining: 38s\n","358:\tlearn: 0.5316684\ttotal: 1m 11s\tremaining: 38s\n","359:\tlearn: 0.5316501\ttotal: 1m 11s\tremaining: 37.8s\n","360:\tlearn: 0.5316501\ttotal: 1m 11s\tremaining: 37.5s\n","361:\tlearn: 0.5315961\ttotal: 1m 12s\tremaining: 37.5s\n","362:\tlearn: 0.5315961\ttotal: 1m 12s\tremaining: 37.2s\n","363:\tlearn: 0.5315000\ttotal: 1m 12s\tremaining: 37.2s\n","364:\tlearn: 0.5313086\ttotal: 1m 13s\tremaining: 37.1s\n","365:\tlearn: 0.5312820\ttotal: 1m 13s\tremaining: 37.2s\n","366:\tlearn: 0.5312086\ttotal: 1m 14s\tremaining: 37.1s\n","367:\tlearn: 0.5311352\ttotal: 1m 15s\tremaining: 37.1s\n","368:\tlearn: 0.5311013\ttotal: 1m 15s\tremaining: 37.1s\n","369:\tlearn: 0.5310559\ttotal: 1m 16s\tremaining: 37s\n","370:\tlearn: 0.5310559\ttotal: 1m 16s\tremaining: 36.7s\n","371:\tlearn: 0.5310557\ttotal: 1m 16s\tremaining: 36.4s\n","372:\tlearn: 0.5310011\ttotal: 1m 16s\tremaining: 36.4s\n","373:\tlearn: 0.5309999\ttotal: 1m 16s\tremaining: 36.1s\n","374:\tlearn: 0.5309996\ttotal: 1m 16s\tremaining: 35.8s\n","375:\tlearn: 0.5309556\ttotal: 1m 17s\tremaining: 35.7s\n","376:\tlearn: 0.5307644\ttotal: 1m 17s\tremaining: 35.7s\n","377:\tlearn: 0.5306913\ttotal: 1m 18s\tremaining: 35.6s\n","378:\tlearn: 0.5306689\ttotal: 1m 18s\tremaining: 35.3s\n","379:\tlearn: 0.5305803\ttotal: 1m 18s\tremaining: 35.3s\n","380:\tlearn: 0.5305546\ttotal: 1m 19s\tremaining: 35.3s\n","381:\tlearn: 0.5303680\ttotal: 1m 20s\tremaining: 35.2s\n","382:\tlearn: 0.5303680\ttotal: 1m 20s\tremaining: 34.9s\n","383:\tlearn: 0.5303518\ttotal: 1m 20s\tremaining: 34.9s\n","384:\tlearn: 0.5302772\ttotal: 1m 21s\tremaining: 34.8s\n","385:\tlearn: 0.5302772\ttotal: 1m 21s\tremaining: 34.5s\n","386:\tlearn: 0.5302772\ttotal: 1m 21s\tremaining: 34.2s\n","387:\tlearn: 0.5302751\ttotal: 1m 21s\tremaining: 33.9s\n","388:\tlearn: 0.5302065\ttotal: 1m 21s\tremaining: 33.7s\n","389:\tlearn: 0.5301988\ttotal: 1m 21s\tremaining: 33.4s\n","390:\tlearn: 0.5301988\ttotal: 1m 21s\tremaining: 33.1s\n","391:\tlearn: 0.5301770\ttotal: 1m 21s\tremaining: 32.9s\n","392:\tlearn: 0.5301456\ttotal: 1m 22s\tremaining: 32.8s\n","393:\tlearn: 0.5301456\ttotal: 1m 22s\tremaining: 32.5s\n","394:\tlearn: 0.5299321\ttotal: 1m 22s\tremaining: 32.4s\n","395:\tlearn: 0.5299301\ttotal: 1m 22s\tremaining: 32.2s\n","396:\tlearn: 0.5299234\ttotal: 1m 22s\tremaining: 31.9s\n","397:\tlearn: 0.5299234\ttotal: 1m 22s\tremaining: 31.6s\n","398:\tlearn: 0.5298886\ttotal: 1m 22s\tremaining: 31.4s\n","399:\tlearn: 0.5298884\ttotal: 1m 22s\tremaining: 31.1s\n","400:\tlearn: 0.5298687\ttotal: 1m 23s\tremaining: 31s\n","401:\tlearn: 0.5298687\ttotal: 1m 23s\tremaining: 30.7s\n","402:\tlearn: 0.5298677\ttotal: 1m 23s\tremaining: 30.4s\n","403:\tlearn: 0.5297681\ttotal: 1m 23s\tremaining: 30.4s\n","404:\tlearn: 0.5297439\ttotal: 1m 24s\tremaining: 30.2s\n","405:\tlearn: 0.5295704\ttotal: 1m 24s\tremaining: 30.1s\n","406:\tlearn: 0.5294798\ttotal: 1m 25s\tremaining: 30.1s\n","407:\tlearn: 0.5293273\ttotal: 1m 26s\tremaining: 30s\n","408:\tlearn: 0.5292137\ttotal: 1m 26s\tremaining: 29.9s\n","409:\tlearn: 0.5292137\ttotal: 1m 26s\tremaining: 29.6s\n","410:\tlearn: 0.5292137\ttotal: 1m 26s\tremaining: 29.3s\n","411:\tlearn: 0.5291958\ttotal: 1m 27s\tremaining: 29.2s\n","412:\tlearn: 0.5291757\ttotal: 1m 27s\tremaining: 29.2s\n","413:\tlearn: 0.5290737\ttotal: 1m 28s\tremaining: 29.1s\n","414:\tlearn: 0.5288900\ttotal: 1m 29s\tremaining: 29s\n","415:\tlearn: 0.5287826\ttotal: 1m 29s\tremaining: 28.9s\n","416:\tlearn: 0.5287826\ttotal: 1m 29s\tremaining: 28.6s\n","417:\tlearn: 0.5287366\ttotal: 1m 30s\tremaining: 28.5s\n","418:\tlearn: 0.5287361\ttotal: 1m 30s\tremaining: 28.2s\n","419:\tlearn: 0.5287091\ttotal: 1m 30s\tremaining: 28.1s\n","420:\tlearn: 0.5286807\ttotal: 1m 31s\tremaining: 28s\n","421:\tlearn: 0.5286151\ttotal: 1m 31s\tremaining: 27.9s\n","422:\tlearn: 0.5286151\ttotal: 1m 32s\tremaining: 27.6s\n","423:\tlearn: 0.5285784\ttotal: 1m 32s\tremaining: 27.5s\n","424:\tlearn: 0.5284103\ttotal: 1m 33s\tremaining: 27.4s\n","425:\tlearn: 0.5283755\ttotal: 1m 33s\tremaining: 27.2s\n","426:\tlearn: 0.5283451\ttotal: 1m 34s\tremaining: 27.1s\n","427:\tlearn: 0.5283451\ttotal: 1m 34s\tremaining: 26.8s\n","428:\tlearn: 0.5283451\ttotal: 1m 34s\tremaining: 26.6s\n","429:\tlearn: 0.5283063\ttotal: 1m 34s\tremaining: 26.4s\n","430:\tlearn: 0.5282456\ttotal: 1m 35s\tremaining: 26.3s\n","431:\tlearn: 0.5281630\ttotal: 1m 35s\tremaining: 26.2s\n","432:\tlearn: 0.5281615\ttotal: 1m 35s\tremaining: 25.9s\n","433:\tlearn: 0.5281615\ttotal: 1m 35s\tremaining: 25.6s\n","434:\tlearn: 0.5280588\ttotal: 1m 36s\tremaining: 25.5s\n","435:\tlearn: 0.5280587\ttotal: 1m 36s\tremaining: 25.2s\n","436:\tlearn: 0.5280136\ttotal: 1m 36s\tremaining: 25.1s\n","437:\tlearn: 0.5279915\ttotal: 1m 37s\tremaining: 24.8s\n","438:\tlearn: 0.5279701\ttotal: 1m 37s\tremaining: 24.7s\n","439:\tlearn: 0.5279662\ttotal: 1m 37s\tremaining: 24.4s\n","440:\tlearn: 0.5279662\ttotal: 1m 37s\tremaining: 24.1s\n","441:\tlearn: 0.5278708\ttotal: 1m 38s\tremaining: 24s\n","442:\tlearn: 0.5277525\ttotal: 1m 38s\tremaining: 23.8s\n","443:\tlearn: 0.5276964\ttotal: 1m 39s\tremaining: 23.7s\n","444:\tlearn: 0.5276963\ttotal: 1m 39s\tremaining: 23.4s\n","445:\tlearn: 0.5276772\ttotal: 1m 39s\tremaining: 23.1s\n","446:\tlearn: 0.5276083\ttotal: 1m 39s\tremaining: 23s\n","447:\tlearn: 0.5276083\ttotal: 1m 39s\tremaining: 22.7s\n","448:\tlearn: 0.5276083\ttotal: 1m 39s\tremaining: 22.5s\n","449:\tlearn: 0.5274913\ttotal: 1m 40s\tremaining: 22.3s\n","450:\tlearn: 0.5274446\ttotal: 1m 40s\tremaining: 22s\n","451:\tlearn: 0.5274188\ttotal: 1m 40s\tremaining: 21.9s\n","452:\tlearn: 0.5273842\ttotal: 1m 41s\tremaining: 21.7s\n","453:\tlearn: 0.5272848\ttotal: 1m 41s\tremaining: 21.6s\n","454:\tlearn: 0.5272502\ttotal: 1m 42s\tremaining: 21.4s\n","455:\tlearn: 0.5272502\ttotal: 1m 42s\tremaining: 21.1s\n","456:\tlearn: 0.5272500\ttotal: 1m 42s\tremaining: 20.9s\n","457:\tlearn: 0.5272497\ttotal: 1m 42s\tremaining: 20.6s\n","458:\tlearn: 0.5270155\ttotal: 1m 43s\tremaining: 20.4s\n","459:\tlearn: 0.5269918\ttotal: 1m 43s\tremaining: 20.3s\n","460:\tlearn: 0.5269219\ttotal: 1m 44s\tremaining: 20.1s\n","461:\tlearn: 0.5268994\ttotal: 1m 44s\tremaining: 19.9s\n","462:\tlearn: 0.5268990\ttotal: 1m 44s\tremaining: 19.7s\n","463:\tlearn: 0.5268799\ttotal: 1m 45s\tremaining: 19.5s\n","464:\tlearn: 0.5268799\ttotal: 1m 45s\tremaining: 19.3s\n","465:\tlearn: 0.5267750\ttotal: 1m 45s\tremaining: 19.1s\n","466:\tlearn: 0.5266846\ttotal: 1m 46s\tremaining: 18.9s\n","467:\tlearn: 0.5266846\ttotal: 1m 46s\tremaining: 18.6s\n","468:\tlearn: 0.5266549\ttotal: 1m 46s\tremaining: 18.5s\n","469:\tlearn: 0.5266547\ttotal: 1m 46s\tremaining: 18.2s\n","470:\tlearn: 0.5266460\ttotal: 1m 47s\tremaining: 17.9s\n","471:\tlearn: 0.5266460\ttotal: 1m 47s\tremaining: 17.7s\n","472:\tlearn: 0.5265952\ttotal: 1m 47s\tremaining: 17.5s\n","473:\tlearn: 0.5265745\ttotal: 1m 48s\tremaining: 17.3s\n","474:\tlearn: 0.5265745\ttotal: 1m 48s\tremaining: 17.1s\n","475:\tlearn: 0.5264800\ttotal: 1m 48s\tremaining: 16.9s\n","476:\tlearn: 0.5264743\ttotal: 1m 49s\tremaining: 16.7s\n","477:\tlearn: 0.5264743\ttotal: 1m 49s\tremaining: 16.4s\n","478:\tlearn: 0.5264420\ttotal: 1m 49s\tremaining: 16.3s\n","479:\tlearn: 0.5264420\ttotal: 1m 49s\tremaining: 16s\n","480:\tlearn: 0.5264215\ttotal: 1m 49s\tremaining: 15.8s\n","481:\tlearn: 0.5263427\ttotal: 1m 50s\tremaining: 15.6s\n","482:\tlearn: 0.5263427\ttotal: 1m 50s\tremaining: 15.3s\n","483:\tlearn: 0.5262348\ttotal: 1m 51s\tremaining: 15.1s\n","484:\tlearn: 0.5261495\ttotal: 1m 51s\tremaining: 14.9s\n","485:\tlearn: 0.5260999\ttotal: 1m 52s\tremaining: 14.8s\n","486:\tlearn: 0.5260305\ttotal: 1m 52s\tremaining: 14.6s\n","487:\tlearn: 0.5260231\ttotal: 1m 52s\tremaining: 14.3s\n","488:\tlearn: 0.5259813\ttotal: 1m 53s\tremaining: 14.1s\n","489:\tlearn: 0.5259143\ttotal: 1m 53s\tremaining: 13.9s\n","490:\tlearn: 0.5259000\ttotal: 1m 54s\tremaining: 13.8s\n","491:\tlearn: 0.5258996\ttotal: 1m 54s\tremaining: 13.5s\n","492:\tlearn: 0.5258652\ttotal: 1m 54s\tremaining: 13.3s\n","493:\tlearn: 0.5258298\ttotal: 1m 55s\tremaining: 13.1s\n","494:\tlearn: 0.5258289\ttotal: 1m 55s\tremaining: 12.8s\n","495:\tlearn: 0.5257082\ttotal: 1m 56s\tremaining: 12.6s\n","496:\tlearn: 0.5255371\ttotal: 1m 56s\tremaining: 12.4s\n","497:\tlearn: 0.5253056\ttotal: 1m 57s\tremaining: 12.2s\n","498:\tlearn: 0.5253029\ttotal: 1m 57s\tremaining: 12s\n","499:\tlearn: 0.5252808\ttotal: 1m 57s\tremaining: 11.7s\n","500:\tlearn: 0.5252267\ttotal: 1m 57s\tremaining: 11.5s\n","501:\tlearn: 0.5251862\ttotal: 1m 58s\tremaining: 11.3s\n","502:\tlearn: 0.5251230\ttotal: 1m 58s\tremaining: 11.1s\n","503:\tlearn: 0.5251230\ttotal: 1m 58s\tremaining: 10.8s\n","504:\tlearn: 0.5251071\ttotal: 1m 58s\tremaining: 10.6s\n","505:\tlearn: 0.5250359\ttotal: 1m 59s\tremaining: 10.4s\n","506:\tlearn: 0.5250359\ttotal: 1m 59s\tremaining: 10.1s\n","507:\tlearn: 0.5250034\ttotal: 1m 59s\tremaining: 9.91s\n","508:\tlearn: 0.5249868\ttotal: 1m 59s\tremaining: 9.66s\n","509:\tlearn: 0.5249868\ttotal: 1m 59s\tremaining: 9.41s\n","510:\tlearn: 0.5249866\ttotal: 1m 59s\tremaining: 9.15s\n","511:\tlearn: 0.5248358\ttotal: 2m\tremaining: 8.95s\n","512:\tlearn: 0.5248357\ttotal: 2m\tremaining: 8.7s\n","513:\tlearn: 0.5247896\ttotal: 2m 1s\tremaining: 8.49s\n","514:\tlearn: 0.5244102\ttotal: 2m 1s\tremaining: 8.27s\n","515:\tlearn: 0.5243661\ttotal: 2m 2s\tremaining: 8.05s\n","516:\tlearn: 0.5243326\ttotal: 2m 2s\tremaining: 7.84s\n","517:\tlearn: 0.5242420\ttotal: 2m 3s\tremaining: 7.62s\n","518:\tlearn: 0.5240976\ttotal: 2m 3s\tremaining: 7.4s\n","519:\tlearn: 0.5240976\ttotal: 2m 3s\tremaining: 7.14s\n","520:\tlearn: 0.5240331\ttotal: 2m 4s\tremaining: 6.93s\n","521:\tlearn: 0.5239966\ttotal: 2m 5s\tremaining: 6.71s\n","522:\tlearn: 0.5239657\ttotal: 2m 5s\tremaining: 6.48s\n","523:\tlearn: 0.5237833\ttotal: 2m 6s\tremaining: 6.26s\n","524:\tlearn: 0.5235952\ttotal: 2m 6s\tremaining: 6.03s\n","525:\tlearn: 0.5235952\ttotal: 2m 6s\tremaining: 5.78s\n","526:\tlearn: 0.5235439\ttotal: 2m 7s\tremaining: 5.55s\n","527:\tlearn: 0.5234923\ttotal: 2m 7s\tremaining: 5.32s\n","528:\tlearn: 0.5234449\ttotal: 2m 8s\tremaining: 5.09s\n","529:\tlearn: 0.5234431\ttotal: 2m 8s\tremaining: 4.84s\n","530:\tlearn: 0.5233876\ttotal: 2m 8s\tremaining: 4.61s\n","531:\tlearn: 0.5233734\ttotal: 2m 8s\tremaining: 4.36s\n","532:\tlearn: 0.5233670\ttotal: 2m 9s\tremaining: 4.13s\n","533:\tlearn: 0.5233670\ttotal: 2m 9s\tremaining: 3.88s\n","534:\tlearn: 0.5233649\ttotal: 2m 9s\tremaining: 3.63s\n","535:\tlearn: 0.5233649\ttotal: 2m 9s\tremaining: 3.38s\n","536:\tlearn: 0.5233649\ttotal: 2m 9s\tremaining: 3.14s\n","537:\tlearn: 0.5233649\ttotal: 2m 9s\tremaining: 2.89s\n","538:\tlearn: 0.5233649\ttotal: 2m 9s\tremaining: 2.64s\n","539:\tlearn: 0.5233013\ttotal: 2m 9s\tremaining: 2.4s\n","540:\tlearn: 0.5232707\ttotal: 2m 10s\tremaining: 2.17s\n","541:\tlearn: 0.5231234\ttotal: 2m 10s\tremaining: 1.93s\n","542:\tlearn: 0.5231234\ttotal: 2m 10s\tremaining: 1.69s\n","543:\tlearn: 0.5231234\ttotal: 2m 10s\tremaining: 1.44s\n","544:\tlearn: 0.5231234\ttotal: 2m 10s\tremaining: 1.2s\n","545:\tlearn: 0.5230606\ttotal: 2m 11s\tremaining: 963ms\n","546:\tlearn: 0.5230441\ttotal: 2m 11s\tremaining: 724ms\n","547:\tlearn: 0.5230441\ttotal: 2m 11s\tremaining: 482ms\n","548:\tlearn: 0.5229560\ttotal: 2m 12s\tremaining: 241ms\n","549:\tlearn: 0.5229553\ttotal: 2m 12s\tremaining: 0us\n"]}],"source":["from catboost import CatBoostClassifier\n","pipeline = imbPipeline(\n","    [\n","        (\"classifier\", CatBoostClassifier(random_state=rng, iterations=550,objective=\"Logloss\",colsample_bylevel=0.0466,depth=12,boosting_type=\"Ordered\",bootstrap_type=\"MVS\",auto_class_weights=\"Balanced\",subsample=0.661\n","                                         )),\n","    ]\n",")\n","cat_features = [i for i in range(len(num_cols_basic+num_cols_imputate),33)]\n","pipeline.fit(X_train, y_train, classifier__cat_features=cat_features,classifier__plot=True)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:06:46.292268Z","iopub.status.busy":"2023-06-03T15:06:46.291683Z","iopub.status.idle":"2023-06-03T15:06:46.483466Z","shell.execute_reply":"2023-06-03T15:06:46.481792Z","shell.execute_reply.started":"2023-06-03T15:06:46.292225Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.39      0.72      0.51      2318\n","           1       0.91      0.70      0.79      8760\n","\n","    accuracy                           0.71     11078\n","   macro avg       0.65      0.71      0.65     11078\n","weighted avg       0.80      0.71      0.73     11078\n","\n","[[1678  640]\n"," [2601 6159]]\n","0.7134910527497724\n"]}],"source":["\n","y_pred = pipeline.predict(X_val)\n","print(classification_report(y_val, y_pred))\n","print(confusion_matrix(y_val, y_pred))\n","from sklearn.metrics import roc_auc_score\n","print(roc_auc_score(y_val,y_pred))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
